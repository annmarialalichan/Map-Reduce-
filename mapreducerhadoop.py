# -*- coding: utf-8 -*-
"""mapreducerHadoop

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1g8S_bgJx2g8yUl9rZm9QjXLb6KzTZkM5
"""

!wget http://qwone.com/~jason/20Newsgroups/20news-18828.tar.gz

!tar -xzvf 20news-18828.tar.gz

!mkdir ~/input1

!cp /content/20news-18828/*/* ~/input1

!cat /content/20news-18828/*/* | python mapper.py | sort | python reducer_py.py

!wget https://downloads.apache.org/hadoop/common/hadoop-3.3.0/hadoop-3.3.0.tar.gz

!tar -xzvf hadoop-3.3.0.tar.gz

!mv hadoop-3.3.0 /usr/local/hadoop

!/usr/local/hadoop/bin/hadoop
!mkdir ~/input
!cp /usr/local/hadoop/etc/hadoop/*.xml ~/input

!/usr/local/hadoop/bin/hadoop jar /usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.0.jar grep ~/input ~/grep_example 'allowed[.]*'

!find / -name 'hadoop-streaming*.jar'

#!/usr/bin/env python
"""mapper.py"""
import io 
import re
import sys
import nltk
from nltk.corpus import stopwords
nltk.download('stopwords',quiet=True)
input_stream = io.TextIOWrapper(sys.stdin.buffer, encoding='latin1')
# input comes from STDIN (standard input)
for line in input_stream:
    line = line.strip() #removes whitespace
    line = re.sub('[^a-zA-Z]', ' ', line) #non alphabets are changed with whitespace
    words = line.split()# split the line into words
    # increase counters
    
    for word in words:
        # write the results to STDOUT (standard output);
        # what we output here will be the input for the
        # Reduce step, i.e. the input for reducer.py
        #
        # tab-delimited; the trivial word count is 1
        if word not in stopwords.words('english'):
          print ('%s\t%s' % (word, 1))

from operator import itemgetter
import sys
import io

current_word = None
current_count = 0
word = None
input_stream = io.TextIOWrapper(sys.stdin.buffer, encoding='latin1')
# input comes from STDIN
for line in input_stream:
    # remove leading and trailing whitespace
    line = line.strip()

    # parse the input we got from mapper.py
    word, count = line.split('\t', 1)

    # convert count (currently a string) to int
    try:
        count = int(count)
    except ValueError:
        # count was not a number, so silently
        # ignore/discard this line
        continue

    # this IF-switch only works because Hadoop sorts map output
    # by key (here: word) before it is passed to the reducer
    if current_word == word:
        current_count += count
    else:
        if current_word:
            # write result to STDOUT
            print ('%s\t%s' % (current_word, current_count))
        current_count = count
        current_word = word

# do not forget to output the last word if needed!
if current_word == word:
    print ('%s\t%s' % (current_word, current_count))

!chmod u+rwx /content/mapper.py
!chmod u+rwx /content/reducer_py.py

rm -rf /content/output

!/usr/local/hadoop/bin/hadoop jar /usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.3.0.jar -input /content/20news-18828/rec.sport.hockey/* -output /content/output -file /content/mapper.py -file /content/reducer_py.py -mapper 'python mapper.py' -reducer 'python reducer_py.py'

!ls /content/output

!cat /content/output/*